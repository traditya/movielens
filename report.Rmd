---
title: "Report on Movielens"
author: "tradityaxx"
date: "9/18/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Download data, wrangle and analysis

File download-data.R is used to download raw data from <http://files.grouplens.org/datasets/movielens/ml-10m.zip>, and then saved under ~/movielens/data/ folder. Subsequently wrangle-data.R is used to create the movielens data which is used for further analysis written in analysis.R as follow:

### 1. 1. Split movielens data into train and validation set

```{r warning=FALSE, message=FALSE}
library(tidyverse)
library(caret)
library(lubridate)
load(file="rda/movielens.rda")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind = "Rounding") 
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(test_index, temp, movielens, removed)

```

### 1. 2. Create smaller dataset for testing purpose

The edx dataset contains ~ 9 millions observations which can take some time to do computation. Thus smaller dataset is created with 10% of the edx dataset

```{r warning=FALSE, message=FALSE}
set.seed(1, sample.kind = "Rounding")
dat_index <- sample(edx$userId, 10^5, replace = FALSE)
dat <- edx[dat_index,]

# Split the data into test and train set
test_index <- createDataPartition(y = dat$rating, times = 1, p = 0.1, list = FALSE)
test_set <- dat[test_index,]
train_set <- dat[-test_index,]

# To make sure test set contains all movieId, userId from train set
test_set <- test_set %>% 
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")
```

## 2. Testing the models

RMSE is used to evaluate the models as follow:

```{r warning=FALSE, message=FALSE}
rmse <- function(pred_rating, actual_rating){
  sqrt(mean((pred_rating - actual_rating)^2))
}
```

### 2. 1. Simple model 

Simple model uses average rating ($\mu$) of all movies as a single predictor. This average
rating can be seen as a baseline when we develop our models by adding other effects later.
The term $\epsilon_{u,i}$ refers to the unexplained errors not captured by $\mu$.

$$Y_{u,i}= \mu + \epsilon_{u,i}$$

```{r warning=FALSE, message=FALSE}
# 1. SIMPLE MODEL
mu <- mean(train_set$rating)

model_1_rmse <- rmse(mu, test_set$rating)
```

### 2. 2. Add movie effect

It makes sense that some movies are just rated higher than other movies, thus we can
add movie effect ($b_{i}$) as follow:

$$Y_{u,i}= \mu + b_{i} + \epsilon_{u,i}$$

```{r warning=FALSE, message=FALSE}
# 2. ADD MOVIE EFFECTS 
movie_avg <- train_set %>% 
  group_by(movieId) %>%
  summarise(b_i = mean(rating - mu)) 

b_i <- test_set %>% 
  left_join(movie_avg, by = "movieId") %>%
  .$b_i

y_hat <- mu + b_i

model_2_rmse <- rmse(y_hat, test_set$rating)  
```

### 2. 3. Add user effect

Furthermore, we know that some users are harsher than others thus tend to give lower
ratings for the same set of movies. We can add user effer ($b_{u}$) as follow:

$$Y_{u,i}= \mu + b_{i} + b_{u} + \epsilon_{u,i}$$

```{r warning=FALSE, message=FALSE}
# 3. ADD USER EFFECTS
user_avg <- train_set %>%
  group_by(userId) %>% 
  left_join(movie_avg, by = "movieId") %>%
  summarise(b_u = mean(rating - mu - b_i))

b_u <- test_set %>%
  left_join(user_avg, by = "userId") %>%
  .$b_u

y_hat <- mu + b_i + b_u

model_3_rmse <- rmse(y_hat, test_set$rating)
```

### 2. 4. Add week effect

We can observe that time has some effects on the ratings of the movie as well, in this case we can see how ratings has some relationship with the week the movies are rated.
So we can further add week effect ($w_{u,i}$)to the previous model:

$$Y_{u,i}= \mu + b_{i} + b_{u} + w_{u,i} + \epsilon_{u,i}$$

Add new column week in the train set
```{r warning=FALSE, message=FALSE}
train_set_week <- train_set %>%
  mutate(date = as_datetime(timestamp), 
         week = round_date(date, unit = "week"))
```

Plot week vs rating and fit the Loess regression to see the relationship
```{r message=FALSE, warning=FALSE}
# Fit with a Loess regression
week <- train_set_week %>% .$week 
total_week <- as.numeric(diff(range(week))) / 7
span <- 150 / total_week

fit <- loess(rating ~ as.numeric(week), degree = 2, 
             span = span, data = train_set_week)

# Plot to see the week effect
train_set_week %>% mutate(smooth = fit$fitted) %>%
  ggplot(aes(week, rating)) + 
  geom_point() +
  geom_line(aes(week, smooth), col = "red", lwd=1)
```

We can see that there is a some relationship between the week the user's u rated movie i. Week effect $w_{u,i}$ can be defined as follow

```{r warning=FALSE, message=FALSE}
# 4. ADD WEEK EFFECT 
train_set_week %>% 
  mutate(week = round_date(date, unit="week"))

week_avg <- train_set_week %>% 
  group_by(week) %>% 
  left_join(movie_avg, by = "movieId") %>%
  left_join(user_avg, by = "userId") %>%
  summarise(w_ui = mean(rating - mu - b_i - b_u))

w_ui <- test_set %>% 
  mutate(date = as_datetime(timestamp), 
         week = round_date(date, unit="week")) %>%
  left_join(movie_avg, by="movieId") %>%
  left_join(user_avg, by="userId") %>%
  left_join(week_avg, by="week") %>%
  .$w_ui
# Now there's only 1 NA when using week effect. Replace NA with mu
w_ui <- replace_na(w_ui, mu)

y_hat <- mu + b_i + b_u + w_ui

model_4_rmse <- rmse(test_set$rating, y_hat)
```

## 2. 5. Add genre effect

Group the train set by genre and plot the average rating with standard error for each genre. Filter the data to contain only genres with more than 1000 ratings

```{r warning=FALSE, message=FALSE}
train_set %>% group_by(genres) %>%
  summarise(n = n(), avg = mean(rating), se = sd(rating)/sqrt(n)) %>%
  filter(n > 1000) %>% 
  ggplot(aes(x = genres, y = avg, ymin = avg - 2*se, ymax = avg + 2*se)) +
  geom_point() +
  geom_errorbar() +
  theme(axis.text.x = element_text(angle=60, hjust=1))
```

## 2.6. Add regularization

To avoid overfitting we can try to add regularization to the previous model, so that
the loss function is defined as follow:

$$\sum_{u,i}(y_{u,i} - \mu - b_i - b_u - w_{u,i})^2 + \lambda (\sum_i b_i^2 + \sum_i b_u^2 + \sum_{u,i} w_{u,i}^2)$$

```{r warning=FALSE, message=FALSE}
# 7. ADD REGULARIZATION FOR MOVIE + USER + WEEK
lambda = 0.75

week_avg_reg <- train_set_week %>% 
  group_by(week) %>% 
  left_join(movie_avg, by = "movieId") %>%
  left_join(user_avg, by = "userId") %>%
  summarise(n=n(), w_ui_reg = sum(rating - mu - b_i - b_u) / (lambda + n) )
  
w_ui_reg <- test_set %>% 
  mutate(date = as_datetime(timestamp), 
         week = round_date(date, unit="week")) %>%
  left_join(movie_avg, by="movieId") %>%
  left_join(user_avg, by="userId") %>%
  left_join(week_avg_reg, by="week") %>%
  .$w_ui_reg
# Now there's only 1 NA when using week effect. Replace NA with mu
w_ui_reg <- replace_na(w_ui_reg, mu)

y_hat <- mu + b_i + b_u + w_ui_reg

model_7_rmse <- rmse(test_set$rating, y_hat)  
```

In order to choose the best value for $\lambda$, we can try several lambdas and choose the one with the smallest RMSE.

```{r warning=FALSE, message=FALSE}
#------------------------------
# CHOOSE BEST LAMBDA
#------------------------------
lambdas <- seq(0, 5, 0.25)

rmses <- sapply(lambdas, function(lambda){
  movie_avg_reg <- train_set %>%
    group_by(movieId) %>% 
    summarise(n=n(), b_i_reg = sum(rating - mu) / (lambda + n) )
  
  user_avg_reg <- train_set %>%
    group_by(userId) %>% 
    left_join(movie_avg, by="movieId") %>%
    summarise(n=n(), b_u_reg = sum(rating - mu - b_i) / (lambda + n) )
  
  b_i_reg <- test_set %>% 
    left_join(movie_avg_reg, by="movieId") %>%
    .$b_i_reg
  
  b_u_reg <- test_set %>% 
    left_join(user_avg_reg, by="userId") %>%
    .$b_u_reg
  
  y_hat <- mu + b_i_reg + b_u_reg
  
  return(rmse(y_hat, test_set$rating))
})
```

The best value for $\lambda$:

```{r warning=FALSE, message=FALSE}
lambda <- lambdas[which.min(rmses)]
lambda
```

Plot the lambdas against RMSE:
```{r warning=FALSE, message=FALSE}
data.frame(lambdas, rmses) %>%
  ggplot(aes(lambdas, rmses)) + geom_point()
```

## 3. Compare the results

```{r echo=FALSE}
rmse_results <- data.frame(Method = c("Simple Model", 
                                      "Movie Model", 
                                      "Movie + User Model", 
                                      "Movie + User + Week Model",
                                      "Regularized Movie + User + Week Model"), 
                           RMSE = c(model_1_rmse, model_2_rmse, model_3_rmse,
                                    model_4_rmse, model_7_rmse))

rmse_results %>% knitr::kable()
```